{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a967e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# conda install -c conda-forge wordcloud\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#importing the required libraries\n",
    "#!pip install wordCloud\n",
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import numpy as np                     \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "# Customise our plotting settings\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "#Libraries for data cleaning and preprocessing\n",
    "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer\n",
    "from sklearn.utils import resample\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#Libraries for data preparation and model building\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score # Classification report\n",
    "\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier,LogisticRegression\n",
    "\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180ca22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training and test data set\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfbba4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset has 15819 rows and 3 columns\n"
     ]
    }
   ],
   "source": [
    "#checking the shape of the training dataframe\n",
    "train.shape\n",
    "print(\"The training dataset has {0} rows and {1} columns\".format(train.shape[0], train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d018af9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d75dbea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for unique values \n",
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3f811c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0aa07_row0_col0 {\n",
       "  background-color: #796eb2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0aa07_row0_col1, #T_0aa07_row1_col0 {\n",
       "  background-color: #3f007d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0aa07_row1_col1 {\n",
       "  background-color: #c9c9e2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0aa07_row2_col0 {\n",
       "  background-color: #c6c7e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0aa07_row2_col1 {\n",
       "  background-color: #eceaf3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0aa07_row3_col0, #T_0aa07_row3_col1 {\n",
       "  background-color: #fcfbfd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0aa07_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >sentiment</th>\n",
       "      <th class=\"col_heading level0 col1\" >message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0aa07_level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "      <td id=\"T_0aa07_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_0aa07_row0_col1\" class=\"data row0 col1\" >8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0aa07_level0_row1\" class=\"row_heading level0 row1\" >3</th>\n",
       "      <td id=\"T_0aa07_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_0aa07_row1_col1\" class=\"data row1 col1\" >3640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0aa07_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "      <td id=\"T_0aa07_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_0aa07_row2_col1\" class=\"data row2 col1\" >2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0aa07_level0_row3\" class=\"row_heading level0 row3\" >0</th>\n",
       "      <td id=\"T_0aa07_row3_col0\" class=\"data row3 col0\" >-1</td>\n",
       "      <td id=\"T_0aa07_row3_col1\" class=\"data row3 col1\" >1296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x164f1eca9d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dist = train.groupby('sentiment').count()['message'].reset_index().sort_values(by='message', ascending=False)\n",
    "df_dist.style.background_gradient(cmap='Purples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e7ae4",
   "metadata": {},
   "source": [
    "Well it looks like we have 4 unique values in the label.\n",
    "\n",
    "Based on the description of the data, here is what each value stands for:\n",
    "\n",
    "    1 Pro: the tweet supports the belief of man-made climate change\n",
    "    2 News: the tweet links to factual news about climate change\n",
    "    0 Neutral: the tweet neither supports nor refutes the belief of man-made climate change\n",
    "    -1 Anti: the tweet does not believe in man-made climate change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c39fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=train.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec006361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        polyscimajor epa chief doesn't think carbon di...\n",
       "1        it's not like we lack evidence of anthropogeni...\n",
       "2        rt @rawstory: researchers say we have three ye...\n",
       "3        #todayinmaker# wired : 2016 was a pivotal year...\n",
       "4        rt @soynoviodetodas: it's 2016, and a racist, ...\n",
       "                               ...                        \n",
       "15814    rt @ezlusztig: they took down the material on ...\n",
       "15815    rt @washingtonpost: how climate change could b...\n",
       "15816    notiven: rt: nytimesworld :what does trump act...\n",
       "15817    rt @sara8smiles: hey liberals the climate chan...\n",
       "15818    rt @chet_cannon: .@kurteichenwald's 'climate c...\n",
       "Name: message, Length: 15819, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking a colser look on the message column\n",
    "df_train['message'] = df_train.message.str.lower()\n",
    "df_train['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "693ab0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new dataframe for the features\n",
    "df = pd.DataFrame(df_train['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8550dcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Punctuation\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a659511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "#function that handles the removal punctuations from the tweets\n",
    "def remove_punct(text):\n",
    "    \"\"\"\n",
    "    the function remove_punction, it takes in a text as input and loops through\n",
    "    the text, if a character is not in string.punctuation then it adds the character\n",
    "    as a string to the text variable\n",
    "    \n",
    "    \"\"\"\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9dafe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes all websites and replaces them with the text 'web-url'\n",
    "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "subs_url = r'url-web'\n",
    "df['message_punct'] = df['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7702c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning \n",
    "def clean_data(texts):\n",
    "    \n",
    "    \"\"\"\n",
    "    clean_data(text), the function further cleans the data using (re)\n",
    "    by removing extract white spaces and non text characters\n",
    "    \n",
    "    \"\"\"\n",
    "    words = list()\n",
    "    for text in texts.split():\n",
    "        # remove non text character from start and end of string\n",
    "        text = re.sub(r'(^\\W+|\\W+$)','',text)\n",
    "#       #remove multiple white spaces\n",
    "        text = re.sub(r'\\s+','',text)\n",
    "#       #remove non text characters and emojis between texts\n",
    "        text = re.sub(r'\\W+',r'',text)\n",
    "#       #remove white space at the end of strings\n",
    "        text = re.sub(r'\\s+$',r'',text)\n",
    "#       #Remove unwanted symbols\n",
    "        text = re.sub(r'[#,@,$_,?*//\"\"]',r'',text)\n",
    "        words.append(text.lower())\n",
    "            \n",
    "        text = [i for i in words if len(i) >= 2]\n",
    "        meaningful_words = [w for w in text if not w in stop]\n",
    "\n",
    "    return \" \".join(meaningful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16165d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the clean_data function\n",
    "df['tweets'] = df['message_punct'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fe0754a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>message_punct</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @rawstory: researchers say we have three ye...</td>\n",
       "      <td>rt @rawstory: researchers say we have three ye...</td>\n",
       "      <td>rt rawstory researchers say three years act cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
       "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war clima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @soynoviodetodas: it's 2016, and a racist, ...</td>\n",
       "      <td>rt @soynoviodetodas: it's 2016, and a racist, ...</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  polyscimajor epa chief doesn't think carbon di...   \n",
       "1  it's not like we lack evidence of anthropogeni...   \n",
       "2  rt @rawstory: researchers say we have three ye...   \n",
       "3  #todayinmaker# wired : 2016 was a pivotal year...   \n",
       "4  rt @soynoviodetodas: it's 2016, and a racist, ...   \n",
       "\n",
       "                                       message_punct  \\\n",
       "0  polyscimajor epa chief doesn't think carbon di...   \n",
       "1  it's not like we lack evidence of anthropogeni...   \n",
       "2  rt @rawstory: researchers say we have three ye...   \n",
       "3  #todayinmaker# wired : 2016 was a pivotal year...   \n",
       "4  rt @soynoviodetodas: it's 2016, and a racist, ...   \n",
       "\n",
       "                                              tweets  \n",
       "0  polyscimajor epa chief doesnt think carbon dio...  \n",
       "1    like lack evidence anthropogenic global warming  \n",
       "2  rt rawstory researchers say three years act cl...  \n",
       "3  todayinmaker wired 2016 pivotal year war clima...  \n",
       "4  rt soynoviodetodas 2016 racist sexist climate ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b6159ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying tokenization to the data set\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "df['tokens'] = df['tweets'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2cf3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying Lammetization\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67b92e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>message_punct</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @rawstory: researchers say we have three ye...</td>\n",
       "      <td>rt @rawstory: researchers say we have three ye...</td>\n",
       "      <td>rt rawstory researchers say three years act cl...</td>\n",
       "      <td>[rt, rawstory, researchers, say, three, years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
       "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war clima...</td>\n",
       "      <td>[todayinmaker, wired, 2016, pivotal, year, war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @soynoviodetodas: it's 2016, and a racist, ...</td>\n",
       "      <td>rt @soynoviodetodas: it's 2016, and a racist, ...</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate ...</td>\n",
       "      <td>[rt, soynoviodetodas, 2016, racist, sexist, cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  polyscimajor epa chief doesn't think carbon di...   \n",
       "1  it's not like we lack evidence of anthropogeni...   \n",
       "2  rt @rawstory: researchers say we have three ye...   \n",
       "3  #todayinmaker# wired : 2016 was a pivotal year...   \n",
       "4  rt @soynoviodetodas: it's 2016, and a racist, ...   \n",
       "\n",
       "                                       message_punct  \\\n",
       "0  polyscimajor epa chief doesn't think carbon di...   \n",
       "1  it's not like we lack evidence of anthropogeni...   \n",
       "2  rt @rawstory: researchers say we have three ye...   \n",
       "3  #todayinmaker# wired : 2016 was a pivotal year...   \n",
       "4  rt @soynoviodetodas: it's 2016, and a racist, ...   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1    like lack evidence anthropogenic global warming   \n",
       "2  rt rawstory researchers say three years act cl...   \n",
       "3  todayinmaker wired 2016 pivotal year war clima...   \n",
       "4  rt soynoviodetodas 2016 racist sexist climate ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [like, lack, evidence, anthropogenic, global, ...  \n",
       "2  [rt, rawstory, researchers, say, three, years,...  \n",
       "3  [todayinmaker, wired, 2016, pivotal, year, war...  \n",
       "4  [rt, soynoviodetodas, 2016, racist, sexist, cl...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60d2884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that handles the process of lemmatization\n",
    "def extract_lemma(words, lemmatizer):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in words])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6ba0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in text]  ##Notice the use of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9208d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling extract_lemma function on the tokens column\n",
    "df['lemma'] = df['tokens'].apply(extract_lemma, args=(lemmatizer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f9945f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>message_punct</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, ...</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @rawstory: researchers say we have three ye...</td>\n",
       "      <td>rt @rawstory: researchers say we have three ye...</td>\n",
       "      <td>rt rawstory researchers say three years act cl...</td>\n",
       "      <td>[rt, rawstory, researchers, say, three, years,...</td>\n",
       "      <td>rt rawstory researcher say three year act clim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
       "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war clima...</td>\n",
       "      <td>[todayinmaker, wired, 2016, pivotal, year, war...</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war clima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @soynoviodetodas: it's 2016, and a racist, ...</td>\n",
       "      <td>rt @soynoviodetodas: it's 2016, and a racist, ...</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate ...</td>\n",
       "      <td>[rt, soynoviodetodas, 2016, racist, sexist, cl...</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  polyscimajor epa chief doesn't think carbon di...   \n",
       "1  it's not like we lack evidence of anthropogeni...   \n",
       "2  rt @rawstory: researchers say we have three ye...   \n",
       "3  #todayinmaker# wired : 2016 was a pivotal year...   \n",
       "4  rt @soynoviodetodas: it's 2016, and a racist, ...   \n",
       "\n",
       "                                       message_punct  \\\n",
       "0  polyscimajor epa chief doesn't think carbon di...   \n",
       "1  it's not like we lack evidence of anthropogeni...   \n",
       "2  rt @rawstory: researchers say we have three ye...   \n",
       "3  #todayinmaker# wired : 2016 was a pivotal year...   \n",
       "4  rt @soynoviodetodas: it's 2016, and a racist, ...   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1    like lack evidence anthropogenic global warming   \n",
       "2  rt rawstory researchers say three years act cl...   \n",
       "3  todayinmaker wired 2016 pivotal year war clima...   \n",
       "4  rt soynoviodetodas 2016 racist sexist climate ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [like, lack, evidence, anthropogenic, global, ...   \n",
       "2  [rt, rawstory, researchers, say, three, years,...   \n",
       "3  [todayinmaker, wired, 2016, pivotal, year, war...   \n",
       "4  [rt, soynoviodetodas, 2016, racist, sexist, cl...   \n",
       "\n",
       "                                               lemma  \n",
       "0  polyscimajor epa chief doesnt think carbon dio...  \n",
       "1    like lack evidence anthropogenic global warming  \n",
       "2  rt rawstory researcher say three year act clim...  \n",
       "3  todayinmaker wired 2016 pivotal year war clima...  \n",
       "4  rt soynoviodetodas 2016 racist sexist climate ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47b2c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine our Label\n",
    "y = df_train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c673febc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['lemma']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9974266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a test dataframe\n",
    "test_df = pd.DataFrame(test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ee648ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0  Europe will now be looking to China to make su...\n",
       "1  Combine this with the polling of staffers re c...\n",
       "2  The scary, unimpeachable evidence that climate...\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07510008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing http and replacing it with url pattern\n",
    "test_df['message_punct'] = test_df['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c051a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the clean_data function\n",
    "test_df['tweets'] = test_df['message_punct'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4117f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying tokenizer\n",
    "test_df['tokens'] = test_df['tweets'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cd44cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the extract_lemma function\n",
    "test_df['lemma'] = test_df['tokens'].apply(extract_lemma, args=(lemmatizer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bf94c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the data using vectorizer\n",
    "test_count = vectorizer.transform(test_df['lemma'].values.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79a6dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the feature\n",
    "x_test = test_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1c37bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10546, 23084)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the shape of the feature\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "112d2ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data (into Training & Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea325893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_linear = LinearSVC(random_state=0, tol=1e-5)\n",
    "svc = SVC()\n",
    "f_clf = RandomForestClassifier(random_state=0)\n",
    "nv_clf = MultinomialNB()\n",
    "lg_clf = LogisticRegression(random_state = 0)\n",
    "passive = PassiveAggressiveClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the models \n",
    "svc.fit(X_train, y_train)\n",
    "f_clf.fit(X_train, y_train)\n",
    "nv_clf.fit(X_train, y_train)\n",
    "lg_clf.fit(X_train, y_train)\n",
    "passive.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83cd346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
